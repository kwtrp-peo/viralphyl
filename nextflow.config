/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    kwtrp-peo/viralphyl Nextflow config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Default config options for all compute environments
----------------------------------------------------------------------------------------
*/

// Global default params, used in configs
params {

    // TODO nf-core: Specify your pipeline's command line flags
    // Input options
    fastq_dir                   = null 
    metadata_tsv                = null
    protocol                    = "amplicon" // [ amplicon, metagenomics ]
    sequencing_summary          = null

    // Output directory
    outdir                      = "${projectDir}/Results"

    // Module options
    skip_assembly               = false
    skip_qc                     = false
    skip_samplesheet_generation = false
    skip_phylogenetics          = false

    // 1. pipeline running parameters
        // a. guppyplex options
    min_read_length             = 10
    max_read_length             = null
    min_read_quality            = null

        // b. minion options
    normalise                   = 100
    clair3_model                = null
    clair3_model_dir            = null
    no_indels                   = false
    multi_ref_file              = null
    primer_match_threshold      = 35
    min_depth                   = 20
    min_mapq                    = 20

        // c. Primer scheme parameters
    ref_fasta                   = null
    ref_bed                     = null

    genotypes                   = true
    sequence_threshold          = 0.7

    // 2. phylogenetics global sequence variables: -1 means null/NA for integer variables
    global_fasta                = null
    global_metadata_tsv         = null
    viral_taxon                 = "HMPV" // [ "HMPV", "HRSV-A", "HRSV-B", 'Human rhinovirus']
    viral_host                  = 'human'
    min_sequence_length         = -1
    max_sequence_length         = -1
    subsample_seed              = 123  // -1 value gives a different seed per run
    subsample_max_sequences     = 250   // max number of global sequences for the phylogenetic tree
    subsample_by                = "country year month" // available opitons "country region year month day"

    // Auspice variables
    color_by                    = 'region'

    // Metagenomics parameters
    skip_classification          = false
    show_organisms               = 3
    human_genome                 = "ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.39_GRCh38.p13/GCF_000001405.39_GRCh38.p13_genomic.fna.gz"
    classifier                   = 'mash' // [ 'mash', 'kraken2' ]
    mash_db                      = "https://gembox.cbcb.umd.edu/mash/refseq.genomes.k21s1000.msh"

    // Boilerplate options
    publish_dir_mode             = 'copy'
    help                         = false
    version                      = null
    trace_report_suffix          = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')// Config options
}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'
includeConfig 'conf/modules_amplicon.config'
includeConfig 'conf/modules_metagenomics.config'

profiles {
    local {
        process.executor = 'local'  // Runs jobs on the local machine instead of a cluster.
        process.maxForks = 4  // Allows up to 4 tasks (samples) to run in parallel.
        process.cpus = 2  // Each task is assigned 1 CPU by default.
        process.memory = '2GB'  // Each task is allocated 2GB of RAM.
        process.time = '2h'  // Each task has a maximum runtime of 2 hours.

        // Restrict maximum resources for all processes
        process.resourceLimits = [
            cpus: 7,       // If needed, a single task can use up to 6 CPUs.
            memory: '14GB', // If needed, a single task can use up to 14GB RAM.
            time: '4h'      // If needed, a single task can run up to 4 hours.
        ]
    }
    standard {
        executor.name = 'local'  // Runs all tasks on the local machine

        executor.cpus = 4        // A total of 4 CPUs available for all running tasks
        executor.memory = 8.GB   // A total of 8GB RAM shared across all tasks

        process {
            resourceLimits = [
                memory: 8.GB,  // A single task can use up to 8GB RAM if needed
                cpus: 4,       // A single task can use up to 4 CPUs if available
                time: 1.h      // A single task can run for a maximum of 1 hour
            ]
        }
    }
    debug {
        dumpHashes              = true
        process.beforeScript    = 'echo $HOSTNAME'
        cleanup                 = false
        nextflow.enable.configProcessNamesValidation = true
    }
    conda {
        conda.enabled           = true
        docker.enabled          = false
        singularity.enabled     = false
        podman.enabled          = false
        shifter.enabled         = false
        charliecloud.enabled    = false
        conda.channels          = ['conda-forge', 'bioconda', 'defaults']
        apptainer.enabled       = false
    }
    mamba {
        conda.enabled           = true
        conda.useMamba          = true
        docker.enabled          = false
        singularity.enabled     = false
        podman.enabled          = false
        shifter.enabled         = false
        charliecloud.enabled    = false
        apptainer.enabled       = false
    }
    docker {
        docker.enabled          = true
        conda.enabled           = false
        singularity.enabled     = false
        podman.enabled          = false
        shifter.enabled         = false
        charliecloud.enabled    = false
        apptainer.enabled       = false
        docker.runOptions       = '-u $(id -u):$(id -g)'
    }
    arm {
        docker.runOptions       = '-u $(id -u):$(id -g) --platform=linux/amd64'
    }
    singularity {
        singularity.enabled     = true
        singularity.autoMounts  = true
        conda.enabled           = false
        docker.enabled          = false
        podman.enabled          = false
        shifter.enabled         = false
        charliecloud.enabled    = false
        apptainer.enabled       = false
        singularity.cacheDir    =  "$projectDir/.singularityCache"

    }
    podman {
        podman.enabled          = true
        conda.enabled           = false
        docker.enabled          = false
        singularity.enabled     = false
        shifter.enabled         = false
        charliecloud.enabled    = false
        apptainer.enabled       = false
    }
    shifter {
        shifter.enabled         = true
        conda.enabled           = false
        docker.enabled          = false
        singularity.enabled     = false
        podman.enabled          = false
        charliecloud.enabled    = false
        apptainer.enabled       = false
    }
    charliecloud {
        charliecloud.enabled    = true
        conda.enabled           = false
        docker.enabled          = false
        singularity.enabled     = false
        podman.enabled          = false
        shifter.enabled         = false
        apptainer.enabled       = false
    }
    apptainer {
        apptainer.enabled       = true
        apptainer.autoMounts    = true
        conda.enabled           = false
        docker.enabled          = false
        singularity.enabled     = false
        podman.enabled          = false
        shifter.enabled         = false
        charliecloud.enabled    = false
    }
    wave {
        apptainer.ociAutoPull   = true
        singularity.ociAutoPull = true
        wave.enabled            = true
        wave.freeze             = true
        wave.strategy           = 'conda,container'
    }
    gitpod {
        executor.name           = 'local'
        executor.cpus           = 4
        executor.memory         = 8.GB
        process {
            resourceLimits = [
                memory: 8.GB,
                cpus  : 4,
                time  : 1.h
            ]
        }
    }
    test_amplicon      { includeConfig 'conf/test_amplicon.config'      }
    test_metagenomics  { includeConfig 'conf/test_metagenomics.config'  }
    test_full { includeConfig 'conf/test_full.config' }
    kemri     { includeConfig 'conf/kemri.config'}
}

// Load kwtrp-peo/viralphyl custom profiles from different institutions.
// TODO nf-core: Optionally, you can add a pipeline-specific nf-core config at https://github.com/nf-core/configs
// includeConfig !System.getenv('NXF_OFFLINE') && params.custom_config_base ? "${params.custom_config_base}/pipeline/viralphyl.config" : "/dev/null"

// Set default registry for Apptainer, Docker, Podman, Charliecloud and Singularity independent of -profile
// Will not be used unless Apptainer / Docker / Podman / Charliecloud / Singularity are enabled
// Set to your registry if you have a mirror of containers
apptainer.registry    = 'quay.io'
docker.registry       = 'quay.io'
podman.registry       = 'quay.io'
singularity.registry  = 'quay.io'
charliecloud.registry = 'quay.io'


// Export these variables to prevent local Python/R libraries from conflicting with those in the container
// The JULIA depot path has been adjusted to a fixed path `/usr/local/share/julia` that needs to be used for packages in the container.
// See https://apeltzer.github.io/post/03-julia-lang-nextflow/ for details on that. Once we have a common agreement on where to keep Julia packages, this is adjustable.

env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
    JULIA_DEPOT_PATH = "/usr/local/share/julia"
}


// Disable process selector warnings by default. Use debug profile to enable warnings.
nextflow.enable.configProcessNamesValidation = false

timeline {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_timeline_${params.trace_report_suffix}.html"
}
report {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_report_${params.trace_report_suffix}.html"
}
trace {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_trace_${params.trace_report_suffix}.txt"
}
dag {
    enabled = true
    file    = "${params.outdir}/pipeline_info/pipeline_dag_${params.trace_report_suffix}.png"
}

manifest {
    name            = 'kwtrp-peo/viralphyl'
    author          = "Samuel Odoyo, Dorcas Okanda and George Githinji" // The author field is deprecated from Nextflow version 24.10.0, use contributors instead
    contributors    = [
        // TODO nf-core: Update the field with the details of the contributors to your pipeline. New with Nextflow version 24.10.0
        [
            name: '',
            affiliation: '',
            email: '',
            github: '',
            contribution: [], // List of contribution types ('author', 'maintainer' or 'contributor')
            orcid: ''
        ],
        [
            name: '',
            affiliation: '',
            email: '',
            github: '',
            contribution: [], // List of contribution types ('author', 'maintainer' or 'contributor')
            orcid: ''
        ],
    ]
    homePage        = 'https://github.com/kwtrp-peo/viralphyl'
    description     = """A bioinformatics pipeline designed for the assembly and phylogenetic analysis of viral samples."""
    mainScript      = 'main.nf'
    defaultBranch   = 'main'
    nextflowVersion = '!>=24.04.2'
    version         = '1.0.0'
    doi             = ''
}

// Load modules.config for DSL2 module specific options
includeConfig 'conf/modules.config'
